_target_: fish_vocoder.data.datamodules.naive.NaiveDataModule

batch_size: 32
val_batch_size: 2
num_workers: 8

collate_fn:
  _target_: fish_vocoder.data.datasets.vocoder.collate_fn
  _partial_: true

datasets:
  train:
    _target_: fish_vocoder.data.datasets.vocoder.VocoderDataset
    root: dataset/train
    transform:
      _target_: torch.nn.Sequential
      _args_:
        - _target_: fish_vocoder.data.transforms.load.LoadAudio
          sampling_rate: ${model.sampling_rate}
        - _target_: fish_vocoder.data.transforms.hq_pitch_shift.RandomHQPitchShift
          probability: 1
          sampling_rate: ${model.sampling_rate}
          pitch_range: 4
        - _target_: fish_vocoder.data.transforms.loudness.RandomLoudness
          probability: 0.9
          loudness_range: [0.1, 0.9]
        - _target_: fish_vocoder.data.transforms.crop.RandomCrop
          probability: 1
          crop_length: "${eval: '${model.hop_length} * 32'}"
        - _target_: fish_vocoder.data.transforms.pad.Pad
          multiple_of: ${model.hop_length}

  val:
    _target_: fish_vocoder.data.datasets.vocoder.VocoderDataset
    root: dataset/valid
    transform:
      _target_: torch.nn.Sequential
      _args_:
        - _target_: fish_vocoder.data.transforms.load.LoadAudio
          sampling_rate: ${model.sampling_rate}
        - _target_: fish_vocoder.data.transforms.crop.RandomCrop
          probability: 1
          crop_length: "${eval: '${model.hop_length} * 1000'}"
        - _target_: fish_vocoder.data.transforms.pad.Pad
          multiple_of: ${model.hop_length}
