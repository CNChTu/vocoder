_target_: torch.nn.ModuleDict
modules:
  encoder:
    _target_: torch.nn.Sequential
    _args_:
      - _target_: fish_vocoder.data.transforms.spectrogram.LinearSpectrogram
        n_fft: ${model.n_fft}
        hop_length: ${model.hop_length}
        win_length: ${model.win_length}
      - _target_: fish_vocoder.modules.encoders.convnext.ConvNeXtEncoder
        input_channels: "${eval: '${model.n_fft} // 2 + 1'}"
        depths: [9, 3]
        dims: [384, "${eval: '${model.latent_size} * 2'}"]
        drop_path_rate: 0.2
        kernel_sizes: [7]
  decoder:
    _target_: fish_vocoder.modules.generators.vocos.VocosGenerator
    backbone:
      _target_: fish_vocoder.modules.encoders.convnext.ConvNeXtEncoder
      input_channels: ${model.latent_size}
      depths: [9, 3]
      dims: [384, 512]
      drop_path_rate: 0.2
      kernel_sizes: [7]
    head:
      _target_: fish_vocoder.modules.generators.hifigan.HiFiGANGenerator
      hop_length: ${model.hop_length}
      upsample_rates: [8, 8, 2, 2, 2]  # aka. strides
      upsample_kernel_sizes: [16, 16, 4, 4, 4]
      resblock_kernel_sizes: [3, 7, 11]
      resblock_dilation_sizes: [[1, 3, 5], [1, 3, 5], [1, 3, 5]]
      num_mels: 512
      upsample_initial_channel: 512
      use_template: false
      pre_conv_kernel_size: 13
      post_conv_kernel_size: 13
